{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from lightgbm import plot_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, SCORERS\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"../data/test.csv\"\n",
    "TRAIN_PATH = \"../data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_PATH, sep=\";\")\n",
    "train_df = pd.read_csv(TRAIN_PATH, sep=\";\")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train_df.dtypes), Counter(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different groups of columns\n",
    "target_column_name = \"TARGET\"\n",
    "id_columns_names = [\"id_contract\", \"id_client\"]\n",
    "bool_columns_names = [\"IP_flag\", \"FLAG_DISQUALIFICATION\"]\n",
    "date_columns_names = [\"SIGN_DATE\", \"DATEFIRSTREG\", \"TAXREG_REGDATE\", \"TAXREGPAY_REGDATE\", \"BIRTHDATE\"]\n",
    "\n",
    "# FLAG_DISQUALIFICATION and BIRTHDATE are not good columns\n",
    "remove_columns_names = [\"FLAG_DISQUALIFICATION\", \"BIRTHDATE\"]\n",
    "\n",
    "real_columns_names = list(test_df.select_dtypes(include=['int64', 'float64']).columns)\n",
    "for column_name in id_columns_names + bool_columns_names + [target_column_name]:\n",
    "    real_columns_names.remove(column_name)\n",
    "\n",
    "cat_columns_names = list(test_df.select_dtypes(include=['object']).columns)\n",
    "for column_name in date_columns_names:\n",
    "    cat_columns_names.remove(column_name)\n",
    "\n",
    "for column_name in remove_columns_names:\n",
    "    for columns_list in [bool_columns_names, date_columns_names, real_columns_names, cat_columns_names]:\n",
    "        if column_name in columns_list:\n",
    "            columns_list.remove(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(train_data: pd.DataFrame, test_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "        returns:\n",
    "            X_train, X_test, y_train\n",
    "    \"\"\"\n",
    "    # get target\n",
    "    y_train = train_data.pop(target_column_name).values\n",
    "\n",
    "    # check the order\n",
    "    test_data = test_data[train_data.columns]\n",
    "\n",
    "    # remove ids\n",
    "    # train_data.drop(id_columns_names, inplace=True, axis=1)\n",
    "    # test_data.drop(id_columns_names, inplace=True, axis=1)\n",
    "\n",
    "    # boolean features\n",
    "    train_bool_columns = train_data[bool_columns_names].copy().fillna(0).astype(\"int\")\n",
    "    test_bool_columns = test_data[bool_columns_names].copy().fillna(0).astype(\"int\")\n",
    "\n",
    "    # real features\n",
    "    train_real_columns = train_data[real_columns_names].copy()\n",
    "    test_real_columns = test_data[real_columns_names].copy()\n",
    "    # fill NaN\n",
    "    # test_real_columns = test_real_columns.fillna(train_real_columns.mean())\n",
    "    # train_real_columns = train_real_columns.fillna(train_real_columns.mean())\n",
    "    # some feature generation...\n",
    "    _test_real_columns = test_real_columns.copy()\n",
    "    _train_real_columns = train_real_columns.copy()\n",
    "    for i, column in enumerate(_test_real_columns.columns):\n",
    "        # print(test_df[column].shape, test_df.iloc[:, i:].shape)\n",
    "        new_test_columns = _test_real_columns.iloc[:, i:].mul(_test_real_columns[column], axis=0)\n",
    "        new_test_columns.columns = [x + \"*\" + column for x in _test_real_columns.columns[i:]]\n",
    "        test_real_columns = pd.concat([test_real_columns, new_test_columns], axis=1)\n",
    "\n",
    "        new_train_columns = _train_real_columns.iloc[:, i:].mul(_train_real_columns[column], axis=0)\n",
    "        new_train_columns.columns = [x + \"*\" + column for x in _train_real_columns.columns[i:]]\n",
    "        train_real_columns = pd.concat([train_real_columns, new_train_columns], axis=1)\n",
    "    # normalization\n",
    "    test_real_columns = (test_real_columns - train_real_columns.mean())/train_real_columns.std()\n",
    "    train_real_columns = (train_real_columns - train_real_columns.mean())/train_real_columns.std()\n",
    "    \n",
    "    # categorial features\n",
    "    train_cat_columns = train_data[cat_columns_names].copy()\n",
    "    test_cat_columns = test_data[cat_columns_names].copy()\n",
    "    # concat\n",
    "    train_set_len = len(train_real_columns)\n",
    "    cat_columns = pd.concat([train_cat_columns, test_cat_columns])\n",
    "    # fill NaN\n",
    "    cat_columns = cat_columns.fillna(\"Unknown\")\n",
    "    # one-hot encoding\n",
    "    cat_columns = pd.get_dummies(cat_columns)\n",
    "    # deconcat\n",
    "    train_cat_columns = cat_columns.iloc[:train_set_len]\n",
    "    test_cat_columns = cat_columns.iloc[train_set_len:]\n",
    "    \n",
    "    # datetime features \n",
    "    # TODO\n",
    "\n",
    "    X_train = pd.concat([train_bool_columns, train_real_columns, train_cat_columns], axis=1)\n",
    "    X_test = pd.concat([test_bool_columns, test_real_columns, test_cat_columns], axis=1)\n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = preproc_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    # 'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [4, 6, 8, 10, 12, 14],\n",
    "    'n_estimators': [100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "grid_cv = GridSearchCV(model, params_grid, cv=5, scoring=\"neg_log_loss\")\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_, grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(random_state=RANDOM_SEED, **grid_cv.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model, max_num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id_contract': test_df.id_contract.values, 'TARGET': preds})\n",
    "df.to_csv('../submissions/subm_01.csv', sep=',', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89810938710b76c7770ae9862621ca404232e9763db2bda43862860389a44a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
