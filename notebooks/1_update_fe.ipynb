{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, plot_importance, early_stopping, log_evaluation\n",
    "from dateparser import parse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import SCORERS \n",
    "import matplotlib.pyplot as plt\n",
    "# import optuna.integration.lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"../data/test.csv\"\n",
    "TRAIN_PATH = \"../data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_PATH, sep=\";\")\n",
    "train_df = pd.read_csv(TRAIN_PATH, sep=\";\")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train_df.dtypes), Counter(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different groups of columns\n",
    "target_column_name = \"TARGET\"\n",
    "id_columns_names = [\"id_contract\", \"id_client\"]\n",
    "bool_columns_names = [\"IP_flag\", \"FLAG_DISQUALIFICATION\", \"EGRPOINCLUDED\"]\n",
    "date_columns_names = [\"SIGN_DATE\", \"DATEFIRSTREG\", \"TAXREG_REGDATE\", \"TAXREGPAY_REGDATE\", \"BIRTHDATE\"]\n",
    "\n",
    "# FLAG_DISQUALIFICATION and BIRTHDATE are not good features\n",
    "remove_columns_names = [\"FLAG_DISQUALIFICATION\", \"BIRTHDATE\"]\n",
    "\n",
    "# float or int types, but categorial features\n",
    "hand_cat_columns_names = [\"OKATO_FED\", \"OKATO_REGIONCODE\"]\n",
    "\n",
    "real_columns_names = list(test_df.select_dtypes(include=['int64', 'float64']).columns)\n",
    "for column_name in id_columns_names + bool_columns_names + hand_cat_columns_names + [target_column_name]:\n",
    "    if column_name in real_columns_names:\n",
    "        real_columns_names.remove(column_name)\n",
    "\n",
    "# OKVED_CODE need preprocessing \n",
    "cat_columns_names = list(test_df.select_dtypes(include=['object']).columns) + hand_cat_columns_names\n",
    "for column_name in date_columns_names:\n",
    "    if column_name in cat_columns_names:\n",
    "        cat_columns_names.remove(column_name)\n",
    "\n",
    "for column_name in remove_columns_names:\n",
    "    for columns_list in [bool_columns_names, date_columns_names, real_columns_names, cat_columns_names]:\n",
    "        if column_name in columns_list:\n",
    "            columns_list.remove(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(train_data: pd.DataFrame, test_data: pd.DataFrame, fill_real_nan: bool = True,\n",
    "                 enable_fe: bool = False) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "        returns:\n",
    "            X_train, X_test, y_train\n",
    "    \"\"\"\n",
    "    # get target\n",
    "    y_train = train_data[target_column_name].values\n",
    "\n",
    "    # # target by id feature\n",
    "    # stat_df = train_data[[\"id_client\", \"TARGET\"]].groupby([\"id_client\"]).mean().reset_index()\n",
    "    # test_ids = set(test_data[\"id_client\"].values)\n",
    "    # stat_dict = dict(filter(lambda x: x[0] in test_ids, zip(stat_df[\"id_client\"], stat_df[\"TARGET\"])))\n",
    "    # # train_id_column = pd.DataFrame({\"id_target\": train_data[\"id_client\"].copy().apply(lambda x: \\\n",
    "    # #                                                  stat_dict[x] if x in stat_dict else None)})\n",
    "    # test_id_column = pd.DataFrame({\"id_target\": test_data[\"id_client\"].copy().apply(lambda x: \\\n",
    "    #                                                 stat_dict[x] if x in stat_dict else None)})\n",
    "    # idxs = list(np.arange(len(train_df[\"id_client\"])))\n",
    "\n",
    "    # train_id_column = pd.DataFrame({\n",
    "    #     \"id_target\": [train_df.iloc[idxs[:i]+idxs[i+1:],:][train_df.iloc[idxs[:i]+idxs[i+1:],:][\"id_client\"]==c_id][\"TARGET\"].mean() \n",
    "    #                   for i, c_id in enumerate(train_df[\"id_client\"])]\n",
    "    # })\n",
    "\n",
    "    # check the order\n",
    "    test_data = test_data[train_data.columns]\n",
    "\n",
    "    # remove ids\n",
    "    # train_data.drop(id_columns_names, inplace=True, axis=1)\n",
    "    # test_data.drop(id_columns_names, inplace=True, axis=1)\n",
    "\n",
    "    # boolean features\n",
    "    train_bool_columns = train_data[bool_columns_names].copy().fillna(0).astype(\"int\")\n",
    "    test_bool_columns = test_data[bool_columns_names].copy().fillna(0).astype(\"int\")\n",
    "\n",
    "\n",
    "    # real features\n",
    "    train_real_columns = train_data[real_columns_names].copy()\n",
    "    test_real_columns = test_data[real_columns_names].copy()\n",
    "    # fill NaN\n",
    "    if fill_real_nan:\n",
    "        test_real_columns = test_real_columns.fillna(train_real_columns.mean())\n",
    "        train_real_columns = train_real_columns.fillna(train_real_columns.mean())\n",
    "    # some feature generation...\n",
    "    if enable_fe:\n",
    "        _test_real_columns = test_real_columns.copy()\n",
    "        _train_real_columns = train_real_columns.copy()\n",
    "        for i, column in enumerate(_test_real_columns.columns):\n",
    "            # print(test_df[column].shape, test_df.iloc[:, i:].shape)\n",
    "            new_test_columns = _test_real_columns.iloc[:, i:].mul(_test_real_columns[column], axis=0)\n",
    "            new_test_columns.columns = [x + \"*\" + column for x in _test_real_columns.columns[i:]]\n",
    "            test_real_columns = pd.concat([test_real_columns, new_test_columns], axis=1)\n",
    "\n",
    "            new_train_columns = _train_real_columns.iloc[:, i:].mul(_train_real_columns[column], axis=0)\n",
    "            new_train_columns.columns = [x + \"*\" + column for x in _train_real_columns.columns[i:]]\n",
    "            train_real_columns = pd.concat([train_real_columns, new_train_columns], axis=1)\n",
    "    # normalization\n",
    "    test_real_columns = (test_real_columns - train_real_columns.mean())/train_real_columns.std()\n",
    "    train_real_columns = (train_real_columns - train_real_columns.mean())/train_real_columns.std()\n",
    "    \n",
    "    # categorial features\n",
    "    train_cat_columns = train_data[cat_columns_names].copy()\n",
    "    test_cat_columns = test_data[cat_columns_names].copy()\n",
    "    # concat\n",
    "    train_set_len = len(train_real_columns)\n",
    "    cat_columns = pd.concat([train_cat_columns, test_cat_columns])\n",
    "    # preprocessing for OKVED_CODE\n",
    "    cat_columns[\"OKVED_CODE\"] = cat_columns[\"OKVED_CODE\"].apply(lambda x: str(x).split(\".\", maxsplit=1)[0])\n",
    "    # fill NaN\n",
    "    cat_columns = cat_columns.fillna(\"Unknown\")\n",
    "    # one-hot encoding\n",
    "    cat_columns = pd.get_dummies(cat_columns)\n",
    "    # deconcat\n",
    "    train_cat_columns = cat_columns.iloc[:train_set_len]\n",
    "    test_cat_columns = cat_columns.iloc[train_set_len:]\n",
    "    \n",
    "    # datetime features\n",
    "    train_date_columns = train_data[date_columns_names].copy()\n",
    "    test_date_columns = test_data[date_columns_names].copy()\n",
    "    # getting year -> real feature\n",
    "    _year_func = lambda x: str(x)[5:9] if str(x).strip() else None\n",
    "    for date_column in train_date_columns.columns:\n",
    "        train_date_columns[date_column] = train_date_columns[date_column].apply(_year_func) \n",
    "        test_date_columns[date_column] = test_date_columns[date_column].apply(_year_func)\n",
    "    train_date_columns = train_date_columns.replace(r'^\\s*$', np.nan, regex=True).astype(\"float\")\n",
    "    test_date_columns = test_date_columns.replace(r'^\\s*$', np.nan, regex=True).astype(\"float\")\n",
    "\n",
    "    # X_train = pd.concat([train_id_column, train_bool_columns, train_real_columns, \n",
    "    #                      train_cat_columns, train_date_columns], axis=1)\n",
    "    X_train = pd.concat([train_bool_columns, train_real_columns, \n",
    "                         train_cat_columns, train_date_columns], axis=1)\n",
    "    # X_test = pd.concat([test_id_column, test_bool_columns, test_real_columns, \n",
    "    #                     test_cat_columns, test_date_columns], axis=1)\n",
    "    X_test = pd.concat([test_bool_columns, test_real_columns, \n",
    "                        test_cat_columns, test_date_columns], axis=1)\n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = preproc_data(train_df, test_df, fill_real_nan=True, enable_fe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5478435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "optuna.logging.set_verbosity(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(objective):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "    params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    print(f\"Best score: {best_score}\\n\")\n",
    "    print(f\"Optimized parameters: {params}\\n\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBM_objective(trial):\n",
    "    _boosting_type = trial.suggest_categorical(\"boosting_type\", [\"dart\", \"goss\", \"gbdt\"])\n",
    "    _num_leaves = trial.suggest_int(\"num_leaves\", 2, 256)\n",
    "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1, log=True)\n",
    "    _max_depth = trial.suggest_int(\"max_depth\", 4, 16)\n",
    "    _n_estimators = trial.suggest_int(\"n_estimators\", 100, 800)\n",
    "    # _feature_fraction = trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "    # _bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "    # _bagging_freq = trial.suggest_int('bagging_freq', 1, 7),\n",
    "    # _min_child_samples = trial.suggest_int('min_child_samples', 5, 100),\n",
    "    \n",
    "    LGBM = LGBMClassifier(\n",
    "        boosting_type=_boosting_type,\n",
    "        num_leaves=_num_leaves,\n",
    "        learning_rate=_learning_rate,\n",
    "        max_depth=_max_depth,\n",
    "        n_estimators=_n_estimators,\n",
    "        # feature_fraction=_feature_fraction,\n",
    "        # bagging_fraction=_bagging_fraction,\n",
    "        # bagging_freq=_bagging_freq,\n",
    "        # min_child_samples=_min_child_samples,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(LGBM, X_train, y_train, cv=kfolds, scoring=\"neg_log_loss\")\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_params = tune(LGBM_objective)\n",
    "\n",
    "model = LGBMClassifier(**LGBM_params, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**LGBM_params, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (13,8)\n",
    "plot_importance(model, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id_contract': test_df.id_contract.values, 'TARGET': preds})\n",
    "df.to_csv('../submissions/subm_01.csv', sep=',', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89810938710b76c7770ae9862621ca404232e9763db2bda43862860389a44a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
